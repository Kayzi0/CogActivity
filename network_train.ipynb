{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import pickle as p\n",
    "import torch\n",
    "from tqdm.notebook import trange\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "\n",
    "from network import ConvNet\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import CogDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for training and evaluation\n",
    "def train(model, num_epochs, train_dataloader, val_dataloader):\n",
    "    losses_train = []\n",
    "    accuracies_train = []\n",
    "    f1_train = []\n",
    "    losses_val = []\n",
    "    accuracies_val = []\n",
    "    f1_val = []\n",
    "\n",
    "    for epoch in trange(num_epochs, unit=\"epochs\"):\n",
    "\n",
    "        # training\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        running_f1 = 0.0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for input, target in train_dataloader:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(input)\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            prediction = torch.argmax(output, dim=1)\n",
    "\n",
    "\n",
    "            for p, t in zip(prediction, target):\n",
    "                if p == t:\n",
    "                    running_accuracy+=1 \n",
    "            #running_f1 += f1_score(target, prediction, average=None)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss /= len(train_dataloader)\n",
    "        running_accuracy /= len(train_dataloader)\n",
    "        #running_f1 /= len(train_dataloader)\n",
    "\n",
    "        losses_train.append(running_loss)\n",
    "        accuracies_train.append(running_accuracy)\n",
    "        #f1_train.append(running_f1)\n",
    "\n",
    "        # output\n",
    "        tqdm.write('Epoch {} (train) -- loss: {:.4f} acc: {:.4f}'.format(epoch, running_loss, running_accuracy))\n",
    "\n",
    "\n",
    "        # validation\n",
    "        with torch.no_grad():\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0\n",
    "            running_f1 = 0.0\n",
    "\n",
    "            for input, target in val_dataloader:\n",
    "\n",
    "                    output = model(input)\n",
    "                    loss = criterion(output, target)\n",
    "\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "                    prediction = torch.argmax(output, dim=1).float()   \n",
    "\n",
    "                    for o, t in zip(prediction, target):\n",
    "                        if o == t:\n",
    "                            running_accuracy+=1 \n",
    "                    #running_f1 += f1_score(target, prediction)\n",
    "\n",
    "            running_loss /= len(val_dataloader)\n",
    "            running_accuracy /= len(val_dataloader)\n",
    "            #running_f1 /= len(val_dataloader)\n",
    "\n",
    "            losses_val.append(running_loss)\n",
    "            accuracies_val.append(running_accuracy)\n",
    "            #f1_val.append(running_f1)\n",
    "\n",
    "            # output\n",
    "            tqdm.write('Epoch {} (valid) -- loss: {:.4f} acc: {:.4f}'.format(epoch, running_loss, running_accuracy))\n",
    "    # make model callable outside this function\n",
    "    train.trained_model = model\n",
    "    train.losses_train = losses_train\n",
    "    train.losses_val = losses_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2284, 8, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "# load data and label files\n",
    "# shape = [2284, 200, 3, 9] --> [datasets, time series, channels, devices]\n",
    "data = p.load(open(r\"data/train.pkl\", \"rb\"))\n",
    "labels = p.load(open(r\"data/labels.pkl\", \"rb\"))\n",
    "print(data.shape)\n",
    "\n",
    "# create datasets\n",
    "train_dataset = CogDataset(data, labels, train=True)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=3, shuffle=True)\n",
    "\n",
    "val_dataset = CogDataset(data, labels, train=False)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=3, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9987, 0.9867, 0.9752, 0.9867, 0.9230, 0.9867, 0.9867, 0.9428, 0.9327,\n",
      "        1.4299, 0.9532, 0.9987, 1.0111, 1.0111, 1.0111, 0.9867, 1.0111, 0.9987,\n",
      "        0.9640, 1.0111, 0.9327, 0.9752, 1.0111, 0.9640, 0.9230, 1.4299, 0.9640,\n",
      "        0.9987, 0.9640, 0.9987, 0.9640, 1.0240, 0.9987, 0.9752, 0.9752, 0.9428,\n",
      "        1.0111, 1.0111, 0.9752, 0.9867, 0.9867, 0.9867, 0.9640, 1.0111, 1.0111,\n",
      "        0.9752, 0.9532, 0.9987, 1.0111, 1.0240, 0.9987, 1.0111, 0.9640, 0.9987,\n",
      "        0.9752])\n"
     ]
    }
   ],
   "source": [
    "label_counts = torch.from_numpy(labels).bincount().float()\n",
    "weights = np.sqrt(1/label_counts)\n",
    "weights /= weights.mean()\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss, optimizer etc.\n",
    "model = ConvNet()\n",
    "criterion = nn.CrossEntropyLoss(weight = weights.double())\n",
    "optimizer = optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68388cb24bf407dbcabe7c551269dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?epochs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 (train) -- loss: 4.0203 acc: 0.0722\n",
      "Epoch 0 (valid) -- loss: 4.0193 acc: 0.0392\n",
      "Epoch 1 (train) -- loss: 4.0148 acc: 0.0591\n",
      "Epoch 1 (valid) -- loss: 4.0150 acc: 0.0654\n",
      "Epoch 2 (train) -- loss: 4.0112 acc: 0.0591\n",
      "Epoch 2 (valid) -- loss: 4.0058 acc: 0.0588\n",
      "Epoch 3 (train) -- loss: 4.0065 acc: 0.0591\n",
      "Epoch 3 (valid) -- loss: 3.9979 acc: 0.0588\n",
      "Epoch 4 (train) -- loss: 3.9975 acc: 0.0722\n",
      "Epoch 4 (valid) -- loss: 3.9865 acc: 0.0784\n",
      "Epoch 5 (train) -- loss: 3.9918 acc: 0.0575\n",
      "Epoch 5 (valid) -- loss: 3.9871 acc: 0.0654\n",
      "Epoch 6 (train) -- loss: 3.9915 acc: 0.0739\n",
      "Epoch 6 (valid) -- loss: 3.9787 acc: 0.0784\n",
      "Epoch 7 (train) -- loss: 3.9903 acc: 0.0690\n",
      "Epoch 7 (valid) -- loss: 3.9742 acc: 0.0915\n",
      "Epoch 8 (train) -- loss: 3.9846 acc: 0.0739\n",
      "Epoch 8 (valid) -- loss: 3.9805 acc: 0.0915\n",
      "Epoch 9 (train) -- loss: 3.9823 acc: 0.0706\n",
      "Epoch 9 (valid) -- loss: 3.9614 acc: 0.0915\n",
      "Epoch 10 (train) -- loss: 3.9736 acc: 0.0821\n",
      "Epoch 10 (valid) -- loss: 3.9642 acc: 0.0915\n",
      "Epoch 11 (train) -- loss: 3.9791 acc: 0.0739\n",
      "Epoch 11 (valid) -- loss: 3.9619 acc: 0.0784\n",
      "Epoch 12 (train) -- loss: 3.9698 acc: 0.0837\n",
      "Epoch 12 (valid) -- loss: 3.9536 acc: 0.1046\n",
      "Epoch 13 (train) -- loss: 3.9663 acc: 0.0887\n",
      "Epoch 13 (valid) -- loss: 3.9475 acc: 0.0915\n",
      "Epoch 14 (train) -- loss: 3.9590 acc: 0.0854\n",
      "Epoch 14 (valid) -- loss: 3.9438 acc: 0.0915\n",
      "Epoch 15 (train) -- loss: 3.9652 acc: 0.0821\n",
      "Epoch 15 (valid) -- loss: 3.9550 acc: 0.0980\n",
      "Epoch 16 (train) -- loss: 3.9581 acc: 0.0870\n",
      "Epoch 16 (valid) -- loss: 3.9520 acc: 0.0850\n",
      "Epoch 17 (train) -- loss: 3.9530 acc: 0.0870\n",
      "Epoch 17 (valid) -- loss: 3.9400 acc: 0.1111\n",
      "Epoch 18 (train) -- loss: 3.9524 acc: 0.0854\n",
      "Epoch 18 (valid) -- loss: 3.9433 acc: 0.0784\n",
      "Epoch 19 (train) -- loss: 3.9525 acc: 0.0985\n",
      "Epoch 19 (valid) -- loss: 3.9343 acc: 0.0915\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "train(model.double(), 20, train_dataloader, val_dataloader)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e85ec9bf098c5427e45e2f632dcd4eeff803b007e1abd287d600879388709c1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
